{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AppleCustomKeras.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO48fscmzWxWWCUMCjrz0Tg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyporse/YOLO/blob/main/AppleCustomKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uscZSjRT2YNT"
      },
      "outputs": [],
      "source": [
        "#Google Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/Gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -la \"/content/Gdrive/MyDrive\"\n",
        "# Check MyDrive"
      ],
      "metadata": {
        "id": "jZULITDG2oFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 (선택적으로 Tensorflow 의 Gpu 버전을 사용)\n",
        "# 사용시 오류가 뜸 GPU 사용에대한 문제가 있는듯\n",
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "id": "lV5KQYAK2yZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check Tensorflow Gpu\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print(\"Found GPU at: {}\".format(device_name))\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "0sYBob7V3KBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "# Define Constants\n",
        "batch_size = 128\n",
        "num_classes = 0\n",
        "epochs = 200\n",
        "CW = 32\n",
        "CH = 32\n",
        "CD = 3\n",
        "model_name = 'apple_custom.h5'\n",
        "tflite_model_name = \"apple_custom.tflite\"\n",
        "COLAB_DARKNET_PATH = '/content/Gdrive/MyDrive/Kobot/YOLO/darknet'\n",
        "YOLO_IMAGE_PATH = COLAB_DARKNET_PATH + '/images/'\n",
        "YOLO_FORMAT_PATH = COLAB_DARKNET_PATH + '/images/'\n",
        "classes = []\n",
        "\n",
        "train_images = []\n",
        "train_labels =[]\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "sample_test_image = 'sample_test.jpg'\n",
        "# Test를 위한 Sample \n",
        "sample_test_label = 0"
      ],
      "metadata": {
        "id": "icgVJXzN4huy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_sample(images, labels, sample_count = 25):\n",
        "    grid_count = math.ceil(math.ceil(math.sqrt(sample_count)))\n",
        "    grid_count = min(grid_count, len(images), len(labels))\n",
        "\n",
        "    plt.figure(figsize=(2*grid_count, 2*grid_count))\n",
        "    for i in range(sample_count):\n",
        "        plt.subplot(grid_count, grid_count, i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.grid(False)\n",
        "        image = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)\n",
        "        plt.imshow(image, cmap=plt.cm.gray)\n",
        "        plt.xlabel(labels[i])\n",
        "    plt.show()\n",
        "\n",
        "def download(path):\n",
        "    try:\n",
        "        from google.colab import files\n",
        "        files.download(path)\n",
        "    except ImportError:\n",
        "        import os\n",
        "        print(\"Error Download:\", os.path.join(os.getcwd(), path))\n",
        "\n",
        "def getROI(size, box):\n",
        "    width_ratio = size[1]\n",
        "    height_ratio = size[0]\n",
        "    x = float(box[1]) * width_ratio\n",
        "    y = float(box[2]) * height_ratio\n",
        "    w = float(box[3]) * width_ratio\n",
        "    h = float(box[4]) * height_ratio\n",
        "    half_width = w/2.0\n",
        "    half_height = h/2.0\n",
        "    startX = int(x-half_width)\n",
        "    startY = int(y-half_height)\n",
        "    endX = int(x+half_width)\n",
        "    endY = int(y+half_height)\n",
        "    return (startY, endY, startX, endX)\n",
        "\n",
        "def imShow(path):\n",
        "    fig = plt.gcf()\n",
        "    #fig.set_size_inches(18,10)\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(cv2.cvtColor(path, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a5b3NgQ25qKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLO의 classes를 채워주는 코드"
      ],
      "metadata": {
        "id": "JeBrnFN77736"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(YOLO_FORMAT_PATH+ 'classes.txt', 'r') as txt:\n",
        "    for line in txt:\n",
        "        name = line.replace(\"\\n\", \"\")\n",
        "        classes.append(name)\n",
        "        num_classes +=1\n",
        "    print(classes, num_classes)"
      ],
      "metadata": {
        "id": "K4RQOlcQ7hjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TRAIN\n",
        "image_count = 0\n",
        "with open(YOLO_FORMAT_PATH + 'train.txt', 'r') as txt:\n",
        "    for line in txt:\n",
        "        file_image_count = 0\n",
        "        image_path = line.replace(\"\\n\",\"\")\n",
        "        img = cv2.imread(image_path)\n",
        "        size = img.shape[:2]\n",
        "        text_path = image_path[:-4] + '.txt'\n",
        "        with open(text_path, 'r') as txt:\n",
        "            for line in txt:\n",
        "                box = line.split()\n",
        "                (startY, endY, startX, endX) = getROI(size, box)\n",
        "                image = cv2.resize(img[startY:endY , startX: endX], (CW,CH), interpolation = cv2.INTER_AREA)\n",
        "                #image = cv2.cvtCOLOR(image, cv2.COLOR_BGR2RGB)\n",
        "                #image = cv2.equalizeHist(image)\n",
        "                #imShow(image)\n",
        "                #print(int(box[0]))\n",
        "                ## 위 주석코드는 오히려 인식률이 떨어진다.\n",
        "\n",
        "                # Updata the list of data and labels, respectively\n",
        "\n",
        "                train_images.append(image)\n",
        "                train_labels.append(int(box[0]))\n",
        "                image_count += 1\n",
        "                file_image_count +=1\n",
        "        print(\"%s : %d images added\" % (image_path, file_image_count))\n",
        "    # Convert the data and labels to Numpy arrays\n",
        "    train_images = np.array(train_images)\n",
        "    train_labels = np.array(train_labels)\n",
        "    # Scalse data to the tange of [0,1]\n",
        "    train_images = train_images.astype(\"float32\") / 255.0\n",
        "    # One-Hot encode the training and trsting labels\n",
        "    train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
        "    print('%d images added' % image_count)"
      ],
      "metadata": {
        "id": "RVlQ_SM-76WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TEST\n",
        "\n",
        "image_count = 0\n",
        "with open(YOLO_FORMAT_PATH + 'test.txt', 'r') as txt:\n",
        "    for line in txt:\n",
        "        file_image_count = 0\n",
        "        image_path = line.replace(\"\\n\",\"\")\n",
        "        img = cv2.imread(image_path)\n",
        "        size = img.shape[:2]\n",
        "        text_path = image_path[:-4] + '.txt'\n",
        "        with open(text_path, 'r') as txt:\n",
        "            for line in txt:\n",
        "                box = line.split()\n",
        "                (startY, endY, startX, endX) = getROI(size, box)\n",
        "                image = cv2.resize(img[startY:endY , startX: endX], (CW,CH), interpolation = cv2.INTER_AREA)\n",
        "                #image = cv2.cvtCOLOR(image, cv2.COLOR_BGR2RGB)\n",
        "                #image = cv2.equalizeHist(image)\n",
        "                #imShow(image)\n",
        "                #print(int(box[0]))\n",
        "                ## 위 주석코드는 오히려 인식률이 떨어진다.\n",
        "                \n",
        "                # Updata the list of data and labels, respectively\n",
        "\n",
        "                test_images.append(image)\n",
        "                test_labels.append(int(box[0]))\n",
        "                image_count += 1\n",
        "                file_image_count +=1\n",
        "        print(\"%s : %d images added\" % (image_path, file_image_count))\n",
        "    # Convert the data and labels to Numpy arrays\n",
        "    test_images = np.array(test_images)\n",
        "    test_labels = np.array(test_labels)\n",
        "    # Scalse data to the tange of [0,1]\n",
        "    test_images = test_images.astype(\"float32\") / 255.0\n",
        "    # One-Hot encode the training and trsting labels\n",
        "    test_labels = keras.utils.to_categorical(test_labels, num_classes)\n",
        "    print('%d images added' % image_count)"
      ],
      "metadata": {
        "id": "FnrddOwVJ2se"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show images in the training dataset.\n",
        "\n",
        "show_number = len(train_images)\n",
        "print(\"Tatal number of Images : %d\"  % show_number)\n",
        "\n",
        "if(show_number >25):\n",
        "    show_number = 25\n",
        "show_sample(train_images, \n",
        "            [ '%s' % classes[np.argmax(label)] for label in train_labels], show_number)"
      ],
      "metadata": {
        "id": "4byhkZDfKsFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputShape = (CH, CW, CD)\n",
        "\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Flatten(input_shape = inputShape),\n",
        "\n",
        "                          keras.layers.Reshape(target_shape = inputShape),\n",
        "                          keras.layers.Conv2D(filters=32, kernel_size=(3,3), activation = tf.nn.relu),\n",
        "                          keras.layers.Conv2D(filters=64, kernel_size =(3,3), activation=tf.nn.relu),\n",
        "                          keras.layers.MaxPooling2D(pool_size =(2,2,)),\n",
        "                          keras.layers.Dropout(0.25),\n",
        "                          keras.layers.Flatten(input_shape=(28,28)),\n",
        "                          keras.layers.Dense(128, activation = tf.nn.relu),\n",
        "                          keras.layers.Dropout(0.5),\n",
        "\n",
        "                          keras.layers.Dense(num_classes, activation= tf.nn.softmax)\n",
        "])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "VKWBLyGsMykY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model as digits_model.h5\n",
        "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint(model_name, save_best_only = True)\n",
        "\n",
        "# Define a callback to monitor val_loss\n",
        "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', \n",
        "                                                 patience =5)"
      ],
      "metadata": {
        "id": "cczHZsT-M60l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model usisng the early stopping callback\n",
        "# earlyStopping을 이번실습에서는 제외한다.\n",
        "\n",
        "history = model.fit(train_images, train_labels,\n",
        "                    validation_data = (test_images, test_labels),\n",
        "                    epochs = epochs, batch_size = batch_size,\n",
        "                    callbacks=[modelCheckpoint])"
      ],
      "metadata": {
        "id": "ilDEsd9FM8iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the digit classification model if you're using Colab,\n",
        "download(model_name)"
      ],
      "metadata": {
        "id": "W8M3bBLwQ-yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Evaluate model\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "fig, loss_ax = plt.subplots()\n",
        "gix, acc_ax = plt.subplots()\n",
        "\n",
        "loss_ax.plot(history.history['loss'], 'ro', label = 'train loss')\n",
        "loss_ax.plot(history.history['val_loss'], 'r:', label= 'val loss')\n",
        "loss_ax.set_xlabel('epoch')\n",
        "loss_ax.set_ylabel('loss')\n",
        "loss_ax.legend(loc='upper left')\n",
        "\n",
        "acc_ax.plot(history.history['accuracy'], 'bp', label = 'train accuracy')\n",
        "acc_ax.plot(history.history['val_accuracy'], 'b:', label= 'val accuracy')\n",
        "acc_ax.set_ylabel('accuracy')\n",
        "acc_ax.legend(loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M5-1gWeLRKNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Predict the labels of digit images in our test dataset.\n",
        "\n",
        "predictions = model.predict(test_images)\n",
        "# Then plot the first 25 test images and their predicted labels.\n",
        "show_number = len(test_images)\n",
        "print('Tatal number of Images : %d' %show_number)\n",
        "if(show_number > 25):\n",
        "    show_number = 25\n",
        "show_sample(test_images, \n",
        "            ['%s[%s]' % (classes[np.argmax(result)], np.argmax(result) == np.argmax(test_labels[idx]))\n",
        "            for idx,result in enumerate(predictions)],\n",
        "            show_number)\n"
      ],
      "metadata": {
        "id": "cDkFN7mmSh-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict Model\n",
        "import random\n",
        "ran = random.randint(0,25)\n",
        "selected_digit = ran\n",
        "\n",
        "result = predictions[selected_digit]\n",
        "result_number = np.argmax(result)\n",
        "label = test_labels[selected_digit]\n",
        "label_number = np.argmax(label)\n",
        "print(\"%s : %.2f [%s]\" % (classes[result_number], result[result_number]*100, classes[label_number]))\n",
        "\n",
        "imShow(test_images[selected_digit])"
      ],
      "metadata": {
        "id": "tgdMbYLpTlbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}